The problem considered is the planning problem in Multi-agent scenario. Unlike traditional Dec-POMDP which uses flat state space, the devised algorithm deals with propositional model of representation. A novelty is established in the paper dealing with the state space representation right from Flat state space representation to belief state notation and then to factored state representation on grounds of belief state. Though the worst case complexity is not enhanced in the algorithm proposed by the authors, it reduces the size of transition model which made it compact.

The main points that makes this algorithm different from others is that it uses Belief state representation and it sticks to Contingent classical planning approach which made it solve larger DEC-POMDP problem at a easy way. Policy tree construction is the main part of solving single agent POMDP problems with contingent planning. Applying this technique to the multi-agent scenario, the authors made a Global Tree Policy which is extension of policy tree construction to multi-agent scenario. Joint action and joint observations are the terms that denotes the action action and observation obtained to each of the agent. Policy Tree deals with a action and a observation at a time instance as it is single agent scenario. As the problem dealt is the multi-agent scenario, actions corresponding to all the agents are represented as a vector, same principle applies to observation. So the node of Global Policy Tree represents a joint action and branch represents joint observation whereas conventional policy tree denotes node as an action and branch as observation.This method of using a global policy is termed as translation method by authors

The complexity of the Dec-pomdp is defined on basis of reaching the goal in time T. For a set of given joint action, if the agents reach goals then the joint action denotes the policy.Belief state at an epoch t is the function of belief state at epoch t-1, joint action taken on belief state t-1 and joint observation after performing joint action in belief state of t-1. 

Factored representation is dealt in such a way that there is flat state space for each of the agent. Each agent's flat state served as a variable for factored representation of multiple agents.PDDL like representation is employed in this algorithm.A relaxation is made interms of sidelining non-deterministic observations and effects to future reasearch.

Another major improvement is in terms of distinguishing states. A runtime discrimination can be done on states which helps in accurate representation of belief states. This distinguishing is done at agent level and at overall multi-agent level.MPSR translation method is employed in obtained so.

Using factored representation, considering the precondition, effects and distinguishability of states, the factored representation is tested for pushing problem of 2*2 grid and 3*3 grid. It is compared with well known algorithms IPG and GMAA-ICE. The results are satisfactory in terms of running time and state space representation. But this algorithm differs with stated algorithm interms of optimality. While the devised algorithm focuses on a valid solution, the other two focuses on obtained optimal solution.

with clear presentation and exact details of every minute aspect and good yielding results in terms of success and space complexity, I nominate this as best papaer.