In order to apply a single reinforcement learning algorithm on several environments, environment-specific algorithm tuning needs to be done and as a result, learning would no longer be autonomous. Based on the success of ensemble learning methods in a wide variety of computational domains such as question answering and recommendation systems, the authors propose the use of ensemble methods in Reinforcement Learning (RL) to obtain good performance across a number of environments and thereby make learning autonomous.  

A novelty score of '3' (or) 'fair' has been assigned for this paper since ensemble approaches are quite popular in machine learning and this paper has only extended its application to the RL domain and shown that it is successful. A technical soundness score of '4' (or) good has been assigned since the explanation for the algorithm design decisions are quite satisfactory but the authors have failed to explain the reasons behind the choice of algorithm parameter settings in the evaluation phase (such as the choice of 0.05 as the fixed exploration rate) and whether variations in these settings would affect the results.

The clarity of presentation is excellent. The authors have explained most of their decisions clearly; the paper is structured well and is easy to understand. Given that this paper is quite short and does not introduce a lot of new concepts, it is most suitable for a poster presentation. I think this paper does not deserve the Best Paper Award since there is not enough novelty in contribution. 

Overall, this is a good paper which makes use of familiar concepts and is easy to understand. I believe this paper is worthy of being accepted.