This paper mainly talks about the domain adaptation problem in sentiment classification. Domain adaptation is to build our models from some fixed source domain, but later we deploy them across one or more different target domains. This problem is also called as cross-domain sentiment classification. The main aim of this problem is to develop a classifier for one domain and use that for a target domain to extract the sentiment. Training the classifier on a particular source domain and using it directly on the target domain cannot produce any good results. In this paper, they propose a novel active learning approach by actively selecting a small amount of labeled data in the target domain. The main challenge in sentiment classification is the domain adaptation. It should be in such a way that the data distribution of source and target domain should not affect the classification accuracy. This paper deals with the problems that rise by adapting the active learning approaches to cross-domain sentiment classification. The two issues are: size of the involved labeled data and secondly, irregular class distribution in training. For the first issue, this papers uses the newly-added labeled data from target domain to train a separate classifier and apply that to both the sample selection strategy and classification algorithm. Two individual classifiers are constructed from the source and target domains separately which are used later for classification. For the second challenge, a label propagation based classification algorithm is proposed that considers both the labeled and unlabeled data and apply it to both the source and target classifiers.                   

Early work on sentiment classification mainly focused on single-domain. For addressing cross-domain classification, several approaches were proposed which use certain features that are both common to source and target domain while constructing the classifier and later use that for classification. some other works focus on building sentiment sensitive thesaurus to perform cross-domain sentiment classification. This work is very different compared to the earlier works in terms of utilizing active learning approach that utilizes the newly-added labeled data in both the sample selection and the classification algorithm.

The algorithm consists of two parts, selecting a small number of informative samples for manual annotation and then training a classifier with the labeled data together with unlabeled data. In the selection strategy, we start with data from labeled source classifier and build the classifier to identify the top-N uncertainty samples as newly added data. Now for k number of times we keep improving and building the target classifier using the newly added data. Output of this approach is automatically labeled target domain data and the target classifier is built. Top-N uncertainty samples from the label-disagrees samples are chosen and sent for human annotation. In the classification step, a graph with both labeled and unlabeled data is built. There is a ranking approach that is used to propagate the labels from the labeled data to the unlabeled data. LP-based source and target classifiers are built which are combined to make the prediction decision for the new test sample.

The approach is interesting the way that the test sample is generated by the algorithm and later classified by the algorithm itself. This approach is sound especially the strength of the algorithm lies in utilizing the information present in the unlabeled target data to build the source and target classifiers. When we do not know anything about the target domain, the best way is to learn from the target domain and test the learning on target domain. Initially it seemed like both training and testing is done on the same data but highly uncertain samples identified by both the source and target classifiers are chosen as test data. Hence, there is no chance that the classifier will be 100% accurate and the explanation is reasonable. It is interesting to see how this algorithm performs on a very small unlabeled target data. I have a strong feeling that this algorithm requires huge amount of both source as well as target data for a better classification. In the experiments, it was not clear about the baseline algorithm they have used - more explanation is appreciated. 

But, the shown results are good compared to the naive approaches of random sampling or uncertainty sampling with combined or single domain data respectively and the overall idea of learning from the unlabeled data is very interesting in the cross-domain sentiment classification. The paper was well-written with good citations too.